{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNlDQWDqnbu/XQQ1QlI0GMz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MammadovN/Machine_Learning/blob/main/projects/06_real-world-apps/movie-recommendation-system/movie_recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow Recommenders and other dependencies\n",
        "!pip install tensorflow tensorflow-recommenders pandas numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAt7YNorwQQ3",
        "outputId": "6ccaccfe-2418-4428-fb2f-867e43c5fb7b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Collecting tensorflow-recommenders\n",
            "  Downloading tensorflow_recommenders-0.7.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading tensorflow_recommenders-0.7.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorflow-recommenders\n",
            "Successfully installed tensorflow-recommenders-0.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "from typing import Dict, Text"
      ],
      "metadata": {
        "id": "Ljd4hiMDwS8z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the MovieLens dataset\n",
        "!wget https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
        "!unzip ml-latest-small.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGJfeugzwTnr",
        "outputId": "bdf8d8c7-0f65-405a-b650-68da731d827d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-05 07:20:53--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 978202 (955K) [application/zip]\n",
            "Saving to: ‘ml-latest-small.zip’\n",
            "\n",
            "ml-latest-small.zip 100%[===================>] 955.28K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-05-05 07:20:53 (6.57 MB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
            "\n",
            "Archive:  ml-latest-small.zip\n",
            "   creating: ml-latest-small/\n",
            "  inflating: ml-latest-small/links.csv  \n",
            "  inflating: ml-latest-small/tags.csv  \n",
            "  inflating: ml-latest-small/ratings.csv  \n",
            "  inflating: ml-latest-small/README.txt  \n",
            "  inflating: ml-latest-small/movies.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ratings and movies data using Pandas\n",
        "ratings_df = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
        "movies_df = pd.read_csv(\"ml-latest-small/movies.csv\")\n",
        "\n",
        "# Convert Pandas DataFrames to TensorFlow datasets\n",
        "ratings = tf.data.Dataset.from_tensor_slices(dict(ratings_df))\n",
        "movies = tf.data.Dataset.from_tensor_slices(dict(movies_df))"
      ],
      "metadata": {
        "id": "4KArEylKzz_4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract unique user IDs\n",
        "unique_user_ids = np.unique(ratings_df[\"userId\"].values.astype(str))\n",
        "\n",
        "# Extract unique movie IDs\n",
        "unique_movie_ids = np.unique(movies_df[\"movieId\"].values.astype(str))\n",
        "\n",
        "# Print the unique IDs\n",
        "print(\"Unique User IDs:\", unique_user_ids)\n",
        "print(\"Unique Movie IDs:\", unique_movie_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06SywBWtwXgO",
        "outputId": "5024ed5d-fae9-4342-bdfe-63b221b7710b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique User IDs: ['1' '10' '100' '101' '102' '103' '104' '105' '106' '107' '108' '109' '11'\n",
            " '110' '111' '112' '113' '114' '115' '116' '117' '118' '119' '12' '120'\n",
            " '121' '122' '123' '124' '125' '126' '127' '128' '129' '13' '130' '131'\n",
            " '132' '133' '134' '135' '136' '137' '138' '139' '14' '140' '141' '142'\n",
            " '143' '144' '145' '146' '147' '148' '149' '15' '150' '151' '152' '153'\n",
            " '154' '155' '156' '157' '158' '159' '16' '160' '161' '162' '163' '164'\n",
            " '165' '166' '167' '168' '169' '17' '170' '171' '172' '173' '174' '175'\n",
            " '176' '177' '178' '179' '18' '180' '181' '182' '183' '184' '185' '186'\n",
            " '187' '188' '189' '19' '190' '191' '192' '193' '194' '195' '196' '197'\n",
            " '198' '199' '2' '20' '200' '201' '202' '203' '204' '205' '206' '207'\n",
            " '208' '209' '21' '210' '211' '212' '213' '214' '215' '216' '217' '218'\n",
            " '219' '22' '220' '221' '222' '223' '224' '225' '226' '227' '228' '229'\n",
            " '23' '230' '231' '232' '233' '234' '235' '236' '237' '238' '239' '24'\n",
            " '240' '241' '242' '243' '244' '245' '246' '247' '248' '249' '25' '250'\n",
            " '251' '252' '253' '254' '255' '256' '257' '258' '259' '26' '260' '261'\n",
            " '262' '263' '264' '265' '266' '267' '268' '269' '27' '270' '271' '272'\n",
            " '273' '274' '275' '276' '277' '278' '279' '28' '280' '281' '282' '283'\n",
            " '284' '285' '286' '287' '288' '289' '29' '290' '291' '292' '293' '294'\n",
            " '295' '296' '297' '298' '299' '3' '30' '300' '301' '302' '303' '304'\n",
            " '305' '306' '307' '308' '309' '31' '310' '311' '312' '313' '314' '315'\n",
            " '316' '317' '318' '319' '32' '320' '321' '322' '323' '324' '325' '326'\n",
            " '327' '328' '329' '33' '330' '331' '332' '333' '334' '335' '336' '337'\n",
            " '338' '339' '34' '340' '341' '342' '343' '344' '345' '346' '347' '348'\n",
            " '349' '35' '350' '351' '352' '353' '354' '355' '356' '357' '358' '359'\n",
            " '36' '360' '361' '362' '363' '364' '365' '366' '367' '368' '369' '37'\n",
            " '370' '371' '372' '373' '374' '375' '376' '377' '378' '379' '38' '380'\n",
            " '381' '382' '383' '384' '385' '386' '387' '388' '389' '39' '390' '391'\n",
            " '392' '393' '394' '395' '396' '397' '398' '399' '4' '40' '400' '401'\n",
            " '402' '403' '404' '405' '406' '407' '408' '409' '41' '410' '411' '412'\n",
            " '413' '414' '415' '416' '417' '418' '419' '42' '420' '421' '422' '423'\n",
            " '424' '425' '426' '427' '428' '429' '43' '430' '431' '432' '433' '434'\n",
            " '435' '436' '437' '438' '439' '44' '440' '441' '442' '443' '444' '445'\n",
            " '446' '447' '448' '449' '45' '450' '451' '452' '453' '454' '455' '456'\n",
            " '457' '458' '459' '46' '460' '461' '462' '463' '464' '465' '466' '467'\n",
            " '468' '469' '47' '470' '471' '472' '473' '474' '475' '476' '477' '478'\n",
            " '479' '48' '480' '481' '482' '483' '484' '485' '486' '487' '488' '489'\n",
            " '49' '490' '491' '492' '493' '494' '495' '496' '497' '498' '499' '5' '50'\n",
            " '500' '501' '502' '503' '504' '505' '506' '507' '508' '509' '51' '510'\n",
            " '511' '512' '513' '514' '515' '516' '517' '518' '519' '52' '520' '521'\n",
            " '522' '523' '524' '525' '526' '527' '528' '529' '53' '530' '531' '532'\n",
            " '533' '534' '535' '536' '537' '538' '539' '54' '540' '541' '542' '543'\n",
            " '544' '545' '546' '547' '548' '549' '55' '550' '551' '552' '553' '554'\n",
            " '555' '556' '557' '558' '559' '56' '560' '561' '562' '563' '564' '565'\n",
            " '566' '567' '568' '569' '57' '570' '571' '572' '573' '574' '575' '576'\n",
            " '577' '578' '579' '58' '580' '581' '582' '583' '584' '585' '586' '587'\n",
            " '588' '589' '59' '590' '591' '592' '593' '594' '595' '596' '597' '598'\n",
            " '599' '6' '60' '600' '601' '602' '603' '604' '605' '606' '607' '608'\n",
            " '609' '61' '610' '62' '63' '64' '65' '66' '67' '68' '69' '7' '70' '71'\n",
            " '72' '73' '74' '75' '76' '77' '78' '79' '8' '80' '81' '82' '83' '84' '85'\n",
            " '86' '87' '88' '89' '9' '90' '91' '92' '93' '94' '95' '96' '97' '98' '99']\n",
            "Unique Movie IDs: ['1' '10' '100' ... '99910' '99917' '99992']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the ratings data\n",
        "def preprocess_data(features):\n",
        "    return {\n",
        "        \"user_id\": tf.strings.as_string(features[\"userId\"]),\n",
        "        \"movie_id\": tf.strings.as_string(features[\"movieId\"])\n",
        "    }, features[\"rating\"]\n",
        "\n",
        "# Preprocess the ratings data\n",
        "train_data = ratings.map(preprocess_data)"
      ],
      "metadata": {
        "id": "4g3UeJQ1y2SL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple ranking model\n",
        "class RankingModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        embedding_dimension = 32\n",
        "\n",
        "        # User embeddings\n",
        "        self.user_embeddings = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(vocabulary=unique_user_ids),\n",
        "            tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
        "        ])\n",
        "\n",
        "        # Movie embeddings\n",
        "        self.movie_embeddings = tf.keras.Sequential([\n",
        "            tf.keras.layers.StringLookup(vocabulary=unique_movie_ids),\n",
        "            tf.keras.layers.Embedding(len(unique_movie_ids) + 1, embedding_dimension)\n",
        "        ])\n",
        "\n",
        "        # Combine features\n",
        "        self.ratings = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(1)\n",
        "        ])\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Extract user_id and movie_id from the dictionary\n",
        "        user_id = inputs[\"user_id\"]  # Access the \"user_id\" key\n",
        "        movie_id = inputs[\"movie_id\"]  # Access the \"movie_id\" key\n",
        "\n",
        "        # Generate embeddings\n",
        "        user_embedding = self.user_embeddings(user_id)\n",
        "        movie_embedding = self.movie_embeddings(movie_id)\n",
        "\n",
        "        # Predict rating\n",
        "        return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))"
      ],
      "metadata": {
        "id": "DsDBjMxlwaI9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RankingModel()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1), loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_data.batch(100), epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6I0-ASZwctJ",
        "outputId": "6720a9b7-74f9-4fc5-b450-a93305fc7e04"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 15ms/step - loss: 2.3232\n",
            "Epoch 2/3\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 1.0390\n",
            "Epoch 3/3\n",
            "\u001b[1m1009/1009\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.9265\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a2196ee0a50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movies(user_id: str, n_recommendations: int = 10):\n",
        "\n",
        "    # 1) Convert all movie IDs (strings) to a tensor\n",
        "    candidate_movie_ids = tf.constant(unique_movie_ids)\n",
        "\n",
        "    # 2) Expand the single user_id into a vector of the same length as candidate_movie_ids\n",
        "    user_ids = tf.repeat(tf.constant([user_id]), repeats=len(candidate_movie_ids))\n",
        "\n",
        "    # 3) Get predicted scores from the model\n",
        "    scores = model(\n",
        "        {\"user_id\": user_ids, \"movie_id\": candidate_movie_ids},\n",
        "        training=False,  # inference mode\n",
        "    )  # shape: (N, 1)\n",
        "    scores = tf.squeeze(scores, axis=1)  # shape: (N,)\n",
        "\n",
        "    # 4) Select the top-k highest scores\n",
        "    top_k = tf.math.top_k(scores, k=n_recommendations)\n",
        "\n",
        "    # 5) Convert movie IDs and scores to NumPy for easy use\n",
        "    recommended_ids = tf.gather(candidate_movie_ids, top_k.indices).numpy().astype(str)\n",
        "    recommended_scores = top_k.values.numpy()\n",
        "\n",
        "    return list(zip(recommended_ids, recommended_scores))\n"
      ],
      "metadata": {
        "id": "kdGxHmdexniH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_user = \"1\"\n",
        "recs = recommend_movies(sample_user, n_recommendations=10)\n",
        "\n",
        "print(f\"\\nTop-10 recommendations for user {sample_user}:\")\n",
        "for movie_id, score in recs:\n",
        "    title = movies_df.loc[movies_df[\"movieId\"] == int(movie_id), \"title\"].item()\n",
        "    print(f\"{title:<60}  (predicted rating: {score:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIXOrRJH31Ip",
        "outputId": "253d5c8c-b9c8-478f-dd5f-1b9c77b7dd87"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top-10 recommendations for user 1:\n",
            "Shawshank Redemption, The (1994)                              (predicted rating: 4.51)\n",
            "Godfather, The (1972)                                         (predicted rating: 4.43)\n",
            "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)  (predicted rating: 4.40)\n",
            "Matrix, The (1999)                                            (predicted rating: 4.40)\n",
            "Fight Club (1999)                                             (predicted rating: 4.39)\n",
            "Pulp Fiction (1994)                                           (predicted rating: 4.39)\n",
            "My Fair Lady (1964)                                           (predicted rating: 4.37)\n",
            "Reservoir Dogs (1992)                                         (predicted rating: 4.37)\n",
            "Rear Window (1954)                                            (predicted rating: 4.36)\n",
            "Monty Python and the Holy Grail (1975)                        (predicted rating: 4.36)\n"
          ]
        }
      ]
    }
  ]
}